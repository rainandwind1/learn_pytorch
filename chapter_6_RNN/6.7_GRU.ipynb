{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d49d24b0b500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m                           \u001b[0mchar_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                           \u001b[0mclipping_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                           prefixes)\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\d2lzh_pytorch\\utils.py\u001b[0m in \u001b[0;36mtrain_and_predict_rnn\u001b[1;34m(rnn, get_params, init_rnn_state, num_hiddens, vocab_size, device, corpus_indices, idx_to_char, char_to_idx, is_random_iter, num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mdata_iter_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_iter_consecutive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d49d24b0b500>\u001b[0m in \u001b[0;36mget_params\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# 输出参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mW_hq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_hiddens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mb_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameterList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW_xz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_q\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "# 循环神经网络常常由于梯度衰减的缘故造成\n",
    "# 它无法在实际应用中博捉到时间序列中较大的依赖关系\n",
    "# gated recurrent NN 通过可以学习的门来控制信息的流动\n",
    "# Gated recurrent unit是一种常用的门控循环神经网络\n",
    "# LSTM是另一种\n",
    "\n",
    "# 门控循环单元 引用了重置门 reset gate 和更新门 update gate\n",
    "# 从而修改了循环神经网络中隐藏状态的计算方式\n",
    "# 重置门和更新门 （LSTM 输入输出和遗忘门）\n",
    "# 重置门和更新门的输入均为当前时间步的输入Xt和上一时间步的隐藏状态Ht-1 ,输出由激活函数为Sigmoid的全连接层得到\n",
    "# 重置门和更新门的输出的值域是【0,1】\n",
    "\n",
    "# 候选隐藏状态\n",
    "# 重置门控制了上一步的隐藏状态如何流入当前时间步的候选隐藏状态，可以用来丢弃\n",
    "# 与预测无关的历史信息\n",
    "\n",
    "# 隐藏状态\n",
    "# 重置门有助于捕捉时间序列短期的依赖关系\n",
    "# 更新门有助于捕捉时间序列里长期的依赖关系（可以有效缓解梯度衰减的问题）\n",
    "\n",
    "# 读取数据集\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()\n",
    "\n",
    "\n",
    "# 从零开始实现GRU\n",
    "# 首先介绍如何从零开始实现门控循环单元\n",
    "# 初始化模型参数\n",
    "\n",
    "num_inputs,num_hiddens,num_outputs = vocab_size,256,vocab_size\n",
    "print('will use',device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size = shape),device = device,dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts,requires_grad=True)\n",
    "    \n",
    "    def _three():\n",
    "        return (_one((num_inputs,num_hiddens)),\n",
    "               _one((num_hiddens,num_hiddens)),\n",
    "               torch.nn.Parameter(torch.zeros(num_hiddens,device=device,dtype=torch.float32),requires_grad=True))\n",
    "    \n",
    "    W_xz,W_hz,b_z = _three()# 更新门参数\n",
    "    W_xr,W_hr,b_r = _three()# 重置门参数\n",
    "    W_xh,W_hh,b_h = _three()# 候选隐藏状态参数\n",
    "    \n",
    "    # 输出参数\n",
    "    W_hq = _one((num_hiddens,num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs),device=device,dtype = torch.float32,requires_grad=True)\n",
    "    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])\n",
    "\n",
    "def init_gru_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),) # ?? why\n",
    "\n",
    "def gru(inputs,state,params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        Z = torch.sigmoid(torch.matmul(X,W_xz) + torch.matmul(H,W_hz) + b_z)\n",
    "        R = torch.sigmoid(torch.matmul(X,W_xr) + torch.matmul(H,W_hr) + b_r)\n",
    "        H_tilda = torch.tanh(torch.matmul(X,W_xh) + R*torch.matmul(H,W_hh) + b_h)\n",
    "        H = Z*H + (1-Z)*H_tilda\n",
    "        Y = torch.matmul(H,W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "        \n",
    "    return outputs,(H,)\n",
    "\n",
    "# 训练模型并创作歌词\n",
    "\n",
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n",
    "\n",
    "\n",
    "d2l.train_and_predict_rnn(gru, get_params, init_gru_state, num_hiddens,\n",
    "                          vocab_size, device, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, False, num_epochs, num_steps, lr,\n",
    "                          clipping_theta, batch_size, pred_period, pred_len,\n",
    "                          prefixes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简洁实现\n",
    "# 在pytorch中我们直接调用nn模块中的GRU类即可\n",
    "lr = 1e-2\n",
    "gru_layer = nn.GRU(input_size = vocab_size,hidden_size = num_hiddens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
