{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1027])\n"
     ]
    }
   ],
   "source": [
    "# 6.2循环神经网络\n",
    "# 6.4 循环神经网络的从零开始实现\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "(corpus_indices,char_to_idx,idx_to_char,vocab_size) = d2l.load_data_jay_lyrics()\n",
    "\n",
    "\n",
    "# one_hot 向量\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(x, n_class, dtype=torch.float32): \n",
    "    # X shape: (batch), output shape: (batch, n_class)\n",
    "    x = x.long()\n",
    "    res = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)\n",
    "    res.scatter_(1, x.view(-1, 1), 1)\n",
    "    return res\n",
    "    \n",
    "x = torch.tensor([0, 2])\n",
    "res = one_hot(x, vocab_size)\n",
    "\n",
    "print(res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027])\n"
     ]
    }
   ],
   "source": [
    "def to_onehot(X,n_class):\n",
    "    return [one_hot(X[:,i],n_class) for i in range(X.shape[1])]\n",
    "\n",
    "X = torch.arange(10).view(2,5)\n",
    "inputs = to_onehot(X,vocab_size)\n",
    "print(len(inputs),inputs[0].shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cpu\n",
      "5 torch.Size([2, 1027]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型参数 隐藏单元个数num_hiddens是一个超参数\n",
    "num_inputs,num_hiddens,num_outputs = vocab_size,256,vocab_size\n",
    "print('will use',device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = _one((num_inputs, num_hiddens))\n",
    "    W_hh = _one((num_hiddens, num_hiddens))\n",
    "    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device, requires_grad=True))\n",
    "    # 输出层参数\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, requires_grad=True))\n",
    "    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])\n",
    "\n",
    "# 定义模型\n",
    "# init_rnn_state来返回初始化的隐藏状态(隐层的记忆初始化)\n",
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)\n",
    "\n",
    "def rnn(inputs,state,params):\n",
    "    W_xh,W_hh,b_h,W_hq,b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X,W_xh) + b_h + torch.matmul(H,W_hh))\n",
    "        Y = torch.matmul(H,W_hq) + b_q\n",
    "        outputs.append(Y)  \n",
    "    return outputs,(H,)\n",
    "\n",
    "\n",
    "# 做个简单的测试来观察输出结果的个数（时间步数），以及第一个时间步的输出层输出的\n",
    "# 形状和隐藏状态的形状\n",
    "num__hiddens = 256\n",
    "state = init_rnn_state(X.shape[0],num_hiddens,device)\n",
    "inputs = to_onehot(X.to(device),vocab_size)\n",
    "params = get_params()\n",
    "outputs,state_new = rnn(inputs,state,params)\n",
    "print(len(outputs),outputs[0].shape,state_new[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开抱公我杂滴换圈重主拉'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义预测函数\n",
    "\n",
    "def predict_rnn(prefix,num_chars,rnn,params,init_rnn_state,\n",
    "                num_hiddens,vocab_size,device,idx_to_char,char_to_idxa):\n",
    "    state = init_rnn_state(1,num__hiddens,device)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        # 将上一个时间步的输出作为当前时间步的输入\n",
    "        X = to_onehot(torch.tensor([[output[-1]]],device = device),vocab_size)\n",
    "        # 计算输出和更新隐藏状态\n",
    "        (Y,state) = rnn(X,state,params)\n",
    "        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])\n",
    "\n",
    "predict_rnn('分开',10,rnn,params,init_rnn_state,num_hiddens,vocab_size,device,\n",
    "           idx_to_char,char_to_idx)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 6, 7, 12, 56, 89]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 快排算法\n",
    "import numpy as np\n",
    "\n",
    "def fast_sort(target):\n",
    "    if target == []:\n",
    "        return target\n",
    "    right_index = []\n",
    "    left_index = []\n",
    "    mid_index = []\n",
    "    mid = target[int(len(target)/2)]\n",
    "    for n in target:\n",
    "        if n < mid:\n",
    "            left_index.append(n)\n",
    "        elif n > mid:\n",
    "            right_index.append(n)\n",
    "        else:\n",
    "            mid_index.append(n)\n",
    "    return  fast_sort(left_index) + mid_index + fast_sort(right_index)\n",
    "\n",
    "fast_sort([12,56,89,1,2,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪梯度\n",
    "def grad_clipping(params,theta,device):\n",
    "    norm = torch.tensor([0.0],device = device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2)/.sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta/norm)\n",
    "            \n",
    "# 应对梯度爆炸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 困惑度 preplexity 来评价语言模型的好坏，困惑度是对交叉熵函数做指数运算得到的数值\n",
    "# 最佳情况下，模型总是把标签类别概率预测为1，此时困惑度为1\n",
    "# 最坏情况下，模型总是把标签的类别概率预测为0，此时困惑度为正无穷\n",
    "# 基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数\n",
    "# 显然，任何一个有效的模型的困惑度必须小于类别个数，在本例中，困惑度必须小于词典\n",
    "# 的大小cocab_size 否则模型的预测效果将不如随机猜测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
