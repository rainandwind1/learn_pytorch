{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环神经网络常常由于梯度衰减的缘故造成\n",
    "# 它无法在实际应用中博捉到时间序列中较大的依赖关系\n",
    "# gated recurrent NN 通过可以学习的门来控制信息的流动\n",
    "# Gated recurrent unit是一种常用的门控循环神经网络\n",
    "# LSTM是另一种\n",
    "\n",
    "# 门控循环单元 引用了重置门 reset gate 和更新门 update gate\n",
    "# 从而修改了循环神经网络中隐藏状态的计算方式\n",
    "# 重置门和更新门 （LSTM 输入输出和遗忘门）\n",
    "# 重置门和更新门的输入均为当前时间步的输入Xt和上一时间步的隐藏状态Ht-1 ,输出由激活函数为Sigmoid的全连接层得到\n",
    "# 重置门和更新门的输出的值域是【0,1】\n",
    "\n",
    "# 候选隐藏状态\n",
    "# 重置门控制了上一步的隐藏状态如何流入当前时间步的候选隐藏状态，可以用来丢弃\n",
    "# 与预测无关的历史信息\n",
    "\n",
    "# 隐藏状态\n",
    "# 重置门有助于捕捉时间序列短期的依赖关系\n",
    "# 更新门有助于捕捉时间序列里长期的依赖关系（可以有效缓解梯度衰减的问题）\n",
    "\n",
    "# 读取数据集\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import d2lzh_pytorch2 as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()\n",
    "\n",
    "\n",
    "# 从零开始实现GRU\n",
    "# 首先介绍如何从零开始实现门控循环单元\n",
    "# 初始化模型参数\n",
    "\n",
    "num_inputs,num_hiddens,num_outputs = vocab_size,256,vocab_size\n",
    "print('will use',device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size = shape),device = device,dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts,requires_grad=True)\n",
    "    \n",
    "    def _three():\n",
    "        return (_one((num_inputs,num_hiddens)),\n",
    "               _one((num_hiddens,num_hiddens)),\n",
    "               torch.nn.Parameter(torch.zeros(num_hiddens,device=device,dtype=torch.float32),requires_grad=True))\n",
    "    \n",
    "    W_xz,W_hz,b_z = _three()# 更新门参数\n",
    "    W_xr,W_hr,b_r = _three()# 重置门参数\n",
    "    W_xh,W_hh,b_h = _three()# 候选隐藏状态参数\n",
    "    \n",
    "    # 输出参数\n",
    "    W_hq = _one((num_hiddens,num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs),device=device,dtype = torch.float32,requires_grad=True)\n",
    "    return nn.ParameterList([[W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])\n",
    "                             \n",
    "# 定义参数\n",
    "# 下面的代码定义了隐藏状态初始化函数init_gru_state\n",
    "def init_gru_state(batch_size,num_hiddens,device):\n",
    "                        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
